\documentclass{beamer}

\usepackage[russian]{babel}
\usepackage[utf8]{inputenc}
\usepackage{cmap}
\usepackage{graphicx}
\usepackage{xspace}
\usepackage{psfrag}

\newcommand{\MARK}[1]{{\bf {\it #1}}}
\newcommand{\CODE}[1]{{\ttfamily #1}}

\setbeamertemplate{footline}[frame number]
\usecolortheme{seahorse}
\beamertemplateshadingbackground{white}{blue!3}

\begin{document}

\begin{frame}
\begin{center}
Жарков Денис\\
\vspace{1cm}
{\Large Исследования алгоритмов классификации статей свободной энциклопедии ``Википедия'' 
на~основе ссылок и второстепенных членов предложений}\\
\end{center}
\end{frame}

\begin{frame}
\frametitle{Основная задача}
Множество статей Википедии рассматривается как множество понятий.
В~начальном состоянии нет~никакой информации о~семантике понятий. 

\vspace{1cm}

В~ходе работы проводится выделение классов понятий, каждому из~которых далее указывается некоторая семантика.
В~научной литературе подобный процесс обычно называется ``классификацией''.
\end{frame}

\begin{frame}
\frametitle{Особенности работы}
\begin{enumerate}
\item {
В~качестве исходных данных Википедия выступает как~большой массив структурированного текста со~связями между статьями.
}

\item {
Для~вспомогательных задач по~обработке естественного языка (получение нормальной формы слов и~пр.) 
используется библиотека Стэнфордского университета \MARK{CoreNLP}.
}

\item{
Процесс кластеризации носит эвристический характер.
}
\end{enumerate}
\end{frame}

\begin{frame}
\frametitle{Полезность работы}

\begin{itemize}
\item {
Определяется принадлежность различных имён собственных некоторому интересующему классу,
которая затем может использоваться в~эвристической оценке содержания текста (например, при спам-фильтрации).
}

\item {
Множеству классов понятий назначается некоторая семантика, которая затем может использоваться в~качестве основы более сложных алгоритмов.
Предполагается, что наличие текста само по~себе не~даёт семантической ценности.
}
\end{itemize}

\end{frame}

\begin{frame}
\frametitle{Подход к задаче}
{\bf Объектом считается:}\\
\begin{enumerate}
\item {
Статья, на которую указывает подлежащее-ссылка.
}
\item {
Сама статья, в которой находится предложение, если подлежащее в
нормальной форме совпадает с заголовком статьи и при этом ссылкой не
является.
}
\end{enumerate}

Объекты {\bf считаются близкими}, если они {\underline{часто}} употребляются в предложениях с одними и теми же второстепенными членами \\

\end{frame}

\begin{frame}

\frametitle{Пример}
\begin{itemize}

\item {
В двадцатом столетии в музее {\bf выставлялась} \underline{Мона Лиза} Леонардо Да Винчи {\it (из статьи о Пушкинском музее)}
}

\item {
\underline{Герника} - громадное полотно, которое было {\bf выставлено} в республиканском павильоне Испании {\it (из статьи о Пабло Пикассо)}
}

\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Подзадачи}
\begin{enumerate}

\item {
Выделение предложений со ссылками из дампа
}
\item {
Морфологический анализ отдельного предложения
}
\item {
}
Сохранение наиболее часто используемых слов в качестве второстепенных членов к каждой статье
\item {
}
Фильтрация общих/малозначимых слов-второстепенных членов
\item {
Кластеризация массива статей
}
\item {
Проверка адекватности полученных кластеров
}

\end{enumerate}
\end{frame}

\begin{frame}
\frametitle{Сложности}
\begin{enumerate}

\item {
11 миллионов страниц (Около 3 миллионов статей)
}
\item {
Необходимо придумать адекватное векторное представление документов и меру расстояния между ними
}
\item {
Нужно найти "эталон" классификации, с которым можно будет сравнивать результаты\\
{\it Возможно использование в этом качестве категорий Википедии}
}

\end{enumerate}
\end{frame}

\end{document}
